<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          com\ica\customer\utilities\CustomerUtilities.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>// Copyright (C) 2011-2012 the original author or authors.
</span>2 <span style=''>// See the LICENCE.txt file distributed with this work for additional
</span>3 <span style=''>// information regarding copyright ownership.
</span>4 <span style=''>//
</span>5 <span style=''>// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
</span>6 <span style=''>// you may not use this file except in compliance with the License.
</span>7 <span style=''>// You may obtain a copy of the License at
</span>8 <span style=''>//
</span>9 <span style=''>// http://www.apache.org/licenses/LICENSE-2.0
</span>10 <span style=''>//
</span>11 <span style=''>// Unless required by applicable law or agreed to in writing, software
</span>12 <span style=''>// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
</span>13 <span style=''>// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
</span>14 <span style=''>// See the License for the specific language governing permissions and
</span>15 <span style=''>// limitations under the License.
</span>16 <span style=''>
</span>17 <span style=''>package com.ica.customer.utilities
</span>18 <span style=''>
</span>19 <span style=''>import scala.util.{Failure, Success, Try}
</span>20 <span style=''>import org.apache.spark.sql.functions.col
</span>21 <span style=''>import org.apache.spark.sql.types.{IntegerType,DoubleType}
</span>22 <span style=''>import org.apache.spark.sql.DataFrame
</span>23 <span style=''>import org.apache.spark.sql.functions._
</span>24 <span style=''>
</span>25 <span style=''>import com.ica.customer.session.SessionInit
</span>26 <span style=''>
</span>27 <span style=''>object CustomerUtilities extends SessionInit {
</span>28 <span style=''>
</span>29 <span style=''>  /**
</span>30 <span style=''>   * Method to find weekwise transaction of each customer's.
</span>31 <span style=''>   * @param customerCall
</span>32 <span style=''>   * @param customerOfferCall
</span>33 <span style=''>   * @param transactionRes
</span>34 <span style=''>   * @return resultOfWeeklyTransaction
</span>35 <span style=''>   */
</span>36 <span style=''>  def customerWiseweeklyStatus(customerCall: DataFrame, customerOfferCall: DataFrame, transactionRes: DataFrame): DataFrame = {
</span>37 <span style=''>
</span>38 <span style=''>    val transactionFlatten =
</span>39 <span style=''>      </span><span style='background: #AEF1AE'>transactionRes.select(col(&quot;sales_week_number&quot;), col(&quot;sales&quot;).cast(DoubleType), col(&quot;customer_id&quot;), col(&quot;offer_id&quot;).alias(&quot;offer_redeemed&quot;))
</span>40 <span style=''></span><span style='background: #AEF1AE'>      .join(
</span>41 <span style=''></span><span style='background: #AEF1AE'>        customerOfferCall.select(col(&quot;week_number&quot;), col(&quot;offer_id&quot;).alias(&quot;offer_received&quot;), col(&quot;cust_id&quot;)),
</span>42 <span style=''></span><span style='background: #AEF1AE'>        transactionRes(&quot;sales_week_number&quot;) === customerOfferCall(&quot;week_number&quot;) &amp;&amp; transactionRes(&quot;customer_id&quot;) === customerOfferCall(&quot;cust_id&quot;), &quot;left&quot;)
</span>43 <span style=''></span><span style='background: #AEF1AE'>      .select(&quot;sales_week_number&quot;, &quot;sales&quot;, &quot;customer_id&quot;, &quot;offer_received&quot;, &quot;offer_redeemed&quot;)</span><span style=''>
</span>44 <span style=''>
</span>45 <span style=''>    val transactionFlattenForWeeklyStatus =
</span>46 <span style=''>      </span><span style='background: #AEF1AE'>transactionFlatten.join(customerCall.select(col(&quot;age&quot;), col(&quot;age_group&quot;),
</span>47 <span style=''></span><span style='background: #AEF1AE'>        col(&quot;cust_id&quot;)), transactionFlatten(&quot;customer_id&quot;) === customerCall(&quot;cust_id&quot;), &quot;left&quot;)
</span>48 <span style=''></span><span style='background: #AEF1AE'>      .select(&quot;sales_week_number&quot;, &quot;sales&quot;, &quot;customer_id&quot;, &quot;offer_received&quot;, &quot;offer_redeemed&quot;, &quot;age&quot;, &quot;age_group&quot;)</span><span style=''>
</span>49 <span style=''>
</span>50 <span style=''>    val resultOfWeeklyTransaction =
</span>51 <span style=''>      </span><span style='background: #AEF1AE'>transactionFlattenForWeeklyStatus.groupBy(&quot;sales_week_number&quot;, &quot;customer_id&quot;, &quot;age&quot;, &quot;age_group&quot;)
</span>52 <span style=''></span><span style='background: #AEF1AE'>      .agg(sum(&quot;sales&quot;).as(&quot;sales_sum&quot;), count(&quot;offer_received&quot;).as(&quot;offer_received_count&quot;),
</span>53 <span style=''></span><span style='background: #AEF1AE'>        count(&quot;offer_redeemed&quot;).as(&quot;offer_redeemed_count&quot;), count(&quot;sales_week_number&quot;).as(&quot;no_of_visit&quot;))
</span>54 <span style=''></span><span style='background: #AEF1AE'>      .orderBy(col(&quot;sales_week_number&quot;).asc, col(&quot;customer_id&quot;).cast(IntegerType).asc)</span><span style=''>
</span>55 <span style=''>    resultOfWeeklyTransaction
</span>56 <span style=''>  }
</span>57 <span style=''>
</span>58 <span style=''>  /**
</span>59 <span style=''>   * Method for derive over all transaction status of every week.
</span>60 <span style=''>   * @param customerWiseweeklyStatus
</span>61 <span style=''>   * @return customerOverAllWeeklyStatus
</span>62 <span style=''>   */
</span>63 <span style=''>  def customerOverAllWeeklyStatus(customerWiseweeklyStatus: DataFrame): DataFrame = {
</span>64 <span style=''>    </span><span style='background: #AEF1AE'>Try {
</span>65 <span style=''></span><span style='background: #AEF1AE'>      val customerOverAllWeeklyStatus = customerWiseweeklyStatus.groupBy(&quot;sales_week_number&quot;).agg(
</span>66 <span style=''></span><span style='background: #AEF1AE'>        count(&quot;customer_id&quot;).cast(IntegerType).as(&quot;customer_count&quot;),
</span>67 <span style=''></span><span style='background: #AEF1AE'>        sum(&quot;offer_received_count&quot;).as(&quot;total_offer_received&quot;), sum(&quot;offer_redeemed_count&quot;)
</span>68 <span style=''></span><span style='background: #AEF1AE'>          .as(&quot;total_offer_redeemed&quot;), sum(&quot;sales_sum&quot;)
</span>69 <span style=''></span><span style='background: #AEF1AE'>          .as(&quot;total_amount&quot;), sum(&quot;no_of_visit&quot;)
</span>70 <span style=''></span><span style='background: #AEF1AE'>          .as(&quot;no_of_visit&quot;))
</span>71 <span style=''></span><span style='background: #AEF1AE'>        .orderBy(col(&quot;sales_week_number&quot;).cast(IntegerType).asc) //.show()
</span>72 <span style=''></span><span style='background: #AEF1AE'>
</span>73 <span style=''></span><span style='background: #AEF1AE'>      customerOverAllWeeklyStatus
</span>74 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>75 <span style=''>    match {
</span>76 <span style=''>      case Success(v)=&gt;v
</span>77 <span style=''>      case Failure(issue) =&gt;
</span>78 <span style=''>        </span><span style='background: #F0ADAD'>throw new NullPointerException(&quot;customerWiseweeklyStatus is null&quot;)</span><span style=''>
</span>79 <span style=''>    }
</span>80 <span style=''>
</span>81 <span style=''>  }
</span>82 <span style=''>
</span>83 <span style=''>  def customerTransactionResult(transaction: DataFrame, customerCall: DataFrame): DataFrame = {
</span>84 <span style=''>
</span>85 <span style=''>    val transactionResult =
</span>86 <span style=''>      </span><span style='background: #AEF1AE'>transaction.join(customerCall, transaction(&quot;customer_id&quot;) === customerCall(&quot;cust_id&quot;), &quot;inner&quot;)
</span>87 <span style=''></span><span style='background: #AEF1AE'>        .select(&quot;transaction_id&quot;, &quot;customer_id&quot;, &quot;product_id&quot;, &quot;store_id&quot;, &quot;offer_id&quot;,
</span>88 <span style=''></span><span style='background: #AEF1AE'>          &quot;sales&quot;, &quot;date&quot;, &quot;sales_week_number&quot;, &quot;day_of_sales_week&quot;, &quot;age_group&quot;)</span><span style=''>
</span>89 <span style=''>    transactionResult
</span>90 <span style=''>  }
</span>91 <span style=''>
</span>92 <span style=''>  /**
</span>93 <span style=''>   * Method to bring agewise transaction of the customer's
</span>94 <span style=''>   * @param transactionAgeGroup
</span>95 <span style=''>   * @return resultAgeGroup
</span>96 <span style=''>   */
</span>97 <span style=''>  def transactionOnAgeGroupWise(transactionAgeGroup: DataFrame): DataFrame = {
</span>98 <span style=''>    </span><span style='background: #AEF1AE'>Try {
</span>99 <span style=''></span><span style='background: #AEF1AE'>      val resultOfAgeGroup = transactionAgeGroup.groupBy(&quot;day_of_sales_week&quot;, &quot;age_group&quot;)
</span>100 <span style=''></span><span style='background: #AEF1AE'>          .agg(count(&quot;day_of_sales_week&quot;).as(&quot;days_count&quot;))
</span>101 <span style=''></span><span style='background: #AEF1AE'>      val resultOfAgeGroupFetch = resultOfAgeGroup.groupBy(&quot;age_group&quot;).agg(max(&quot;days_count&quot;).as(&quot;total&quot;))
</span>102 <span style=''></span><span style='background: #AEF1AE'>      val resultAgeGroup =
</span>103 <span style=''></span><span style='background: #AEF1AE'>        resultOfAgeGroup.join(resultOfAgeGroupFetch, resultOfAgeGroup(&quot;age_group&quot;) === resultOfAgeGroupFetch(&quot;age_group&quot;)
</span>104 <span style=''></span><span style='background: #AEF1AE'>          &amp;&amp; resultOfAgeGroup(&quot;days_count&quot;) === resultOfAgeGroupFetch(&quot;total&quot;))
</span>105 <span style=''></span><span style='background: #AEF1AE'>        .select(resultOfAgeGroup(&quot;day_of_sales_week&quot;), resultOfAgeGroup(&quot;age_group&quot;), resultOfAgeGroupFetch(&quot;total&quot;))
</span>106 <span style=''></span><span style='background: #AEF1AE'>      resultAgeGroup
</span>107 <span style=''></span><span style='background: #AEF1AE'>    }</span><span style=''>
</span>108 <span style=''>    match {
</span>109 <span style=''>      case Success(v)=&gt;v
</span>110 <span style=''>      case Failure(issue) =&gt;
</span>111 <span style=''>        </span><span style='background: #AEF1AE'>throw new NullPointerException(&quot;transactionAgeGroup is null&quot;)</span><span style=''>
</span>112 <span style=''>    }
</span>113 <span style=''>  }
</span>114 <span style=''>
</span>115 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Code</th>
      </tr><tr>
        <td>
          43
        </td>
        <td>
          99
        </td>
        <td>
          1477
          -
          1995
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Dataset.select
        </td>
        <td style="background: #AEF1AE">
          transactionRes.select(org.apache.spark.sql.functions.col(&quot;sales_week_number&quot;), org.apache.spark.sql.functions.col(&quot;sales&quot;).cast(org.apache.spark.sql.types.DoubleType), org.apache.spark.sql.functions.col(&quot;customer_id&quot;), org.apache.spark.sql.functions.col(&quot;offer_id&quot;).alias(&quot;offer_redeemed&quot;)).join(customerOfferCall.select(org.apache.spark.sql.functions.col(&quot;week_number&quot;), org.apache.spark.sql.functions.col(&quot;offer_id&quot;).alias(&quot;offer_received&quot;), org.apache.spark.sql.functions.col(&quot;cust_id&quot;)), transactionRes.apply(&quot;sales_week_number&quot;).===(customerOfferCall.apply(&quot;week_number&quot;)).&amp;&amp;(transactionRes.apply(&quot;customer_id&quot;).===(customerOfferCall.apply(&quot;cust_id&quot;))), &quot;left&quot;).select(&quot;sales_week_number&quot;, &quot;sales&quot;, &quot;customer_id&quot;, &quot;offer_received&quot;, &quot;offer_redeemed&quot;)
        </td>
      </tr><tr>
        <td>
          48
        </td>
        <td>
          100
        </td>
        <td>
          2050
          -
          2336
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Dataset.select
        </td>
        <td style="background: #AEF1AE">
          transactionFlatten.join(customerCall.select(org.apache.spark.sql.functions.col(&quot;age&quot;), org.apache.spark.sql.functions.col(&quot;age_group&quot;), org.apache.spark.sql.functions.col(&quot;cust_id&quot;)), transactionFlatten.apply(&quot;customer_id&quot;).===(customerCall.apply(&quot;cust_id&quot;)), &quot;left&quot;).select(&quot;sales_week_number&quot;, &quot;sales&quot;, &quot;customer_id&quot;, &quot;offer_received&quot;, &quot;offer_redeemed&quot;, &quot;age&quot;, &quot;age_group&quot;)
        </td>
      </tr><tr>
        <td>
          51
        </td>
        <td>
          101
        </td>
        <td>
          2425
          -
          2444
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;sales_week_number&quot;
        </td>
      </tr><tr>
        <td>
          51
        </td>
        <td>
          104
        </td>
        <td>
          2468
          -
          2479
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;age_group&quot;
        </td>
      </tr><tr>
        <td>
          51
        </td>
        <td>
          103
        </td>
        <td>
          2461
          -
          2466
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;age&quot;
        </td>
      </tr><tr>
        <td>
          51
        </td>
        <td>
          102
        </td>
        <td>
          2446
          -
          2459
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;customer_id&quot;
        </td>
      </tr><tr>
        <td>
          52
        </td>
        <td>
          106
        </td>
        <td>
          2523
          -
          2573
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Column.as
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.functions.count(&quot;offer_received&quot;).as(&quot;offer_received_count&quot;)
        </td>
      </tr><tr>
        <td>
          52
        </td>
        <td>
          105
        </td>
        <td>
          2493
          -
          2521
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Column.as
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.functions.sum(&quot;sales&quot;).as(&quot;sales_sum&quot;)
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          107
        </td>
        <td>
          2584
          -
          2634
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Column.as
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.functions.count(&quot;offer_redeemed&quot;).as(&quot;offer_redeemed_count&quot;)
        </td>
      </tr><tr>
        <td>
          53
        </td>
        <td>
          108
        </td>
        <td>
          2636
          -
          2680
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Column.as
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.functions.count(&quot;sales_week_number&quot;).as(&quot;no_of_visit&quot;)
        </td>
      </tr><tr>
        <td>
          54
        </td>
        <td>
          110
        </td>
        <td>
          2698
          -
          2726
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.Column.asc
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.functions.col(&quot;sales_week_number&quot;).asc
        </td>
      </tr><tr>
        <td>
          54
        </td>
        <td>
          113
        </td>
        <td>
          2728
          -
          2768
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.Column.asc
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.functions.col(&quot;customer_id&quot;).cast(org.apache.spark.sql.types.IntegerType).asc
        </td>
      </tr><tr>
        <td>
          54
        </td>
        <td>
          109
        </td>
        <td>
          2702
          -
          2721
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;sales_week_number&quot;
        </td>
      </tr><tr>
        <td>
          54
        </td>
        <td>
          112
        </td>
        <td>
          2752
          -
          2763
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.types.IntegerType
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.types.IntegerType
        </td>
      </tr><tr>
        <td>
          54
        </td>
        <td>
          114
        </td>
        <td>
          2383
          -
          2769
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Dataset.orderBy
        </td>
        <td style="background: #AEF1AE">
          transactionFlattenForWeeklyStatus.groupBy(&quot;sales_week_number&quot;, &quot;customer_id&quot;, &quot;age&quot;, &quot;age_group&quot;).agg(org.apache.spark.sql.functions.sum(&quot;sales&quot;).as(&quot;sales_sum&quot;), org.apache.spark.sql.functions.count(&quot;offer_received&quot;).as(&quot;offer_received_count&quot;), org.apache.spark.sql.functions.count(&quot;offer_redeemed&quot;).as(&quot;offer_redeemed_count&quot;), org.apache.spark.sql.functions.count(&quot;sales_week_number&quot;).as(&quot;no_of_visit&quot;)).orderBy(org.apache.spark.sql.functions.col(&quot;sales_week_number&quot;).asc, org.apache.spark.sql.functions.col(&quot;customer_id&quot;).cast(org.apache.spark.sql.types.IntegerType).asc)
        </td>
      </tr><tr>
        <td>
          54
        </td>
        <td>
          111
        </td>
        <td>
          2732
          -
          2745
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;customer_id&quot;
        </td>
      </tr><tr>
        <td>
          64
        </td>
        <td>
          125
        </td>
        <td>
          3061
          -
          3588
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Try.apply
        </td>
        <td style="background: #AEF1AE">
          scala.util.Try.apply[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]]({
  val customerOverAllWeeklyStatus: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = customerWiseweeklyStatus.groupBy(&quot;sales_week_number&quot;).agg(org.apache.spark.sql.functions.count(&quot;customer_id&quot;).cast(org.apache.spark.sql.types.IntegerType).as(&quot;customer_count&quot;), org.apache.spark.sql.functions.sum(&quot;offer_received_count&quot;).as(&quot;total_offer_received&quot;), org.apache.spark.sql.functions.sum(&quot;offer_redeemed_count&quot;).as(&quot;total_offer_redeemed&quot;), org.apache.spark.sql.functions.sum(&quot;sales_sum&quot;).as(&quot;total_amount&quot;), org.apache.spark.sql.functions.sum(&quot;no_of_visit&quot;).as(&quot;no_of_visit&quot;)).orderBy(org.apache.spark.sql.functions.col(&quot;sales_week_number&quot;).cast(org.apache.spark.sql.types.IntegerType).asc);
  customerOverAllWeeklyStatus
})
        </td>
      </tr><tr>
        <td>
          65
        </td>
        <td>
          115
        </td>
        <td>
          3141
          -
          3160
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;sales_week_number&quot;
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          116
        </td>
        <td>
          3176
          -
          3235
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Column.as
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.functions.count(&quot;customer_id&quot;).cast(org.apache.spark.sql.types.IntegerType).as(&quot;customer_count&quot;)
        </td>
      </tr><tr>
        <td>
          67
        </td>
        <td>
          117
        </td>
        <td>
          3246
          -
          3300
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Column.as
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.functions.sum(&quot;offer_received_count&quot;).as(&quot;total_offer_received&quot;)
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          118
        </td>
        <td>
          3302
          -
          3368
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Column.as
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.functions.sum(&quot;offer_redeemed_count&quot;).as(&quot;total_offer_redeemed&quot;)
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          119
        </td>
        <td>
          3370
          -
          3417
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Column.as
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.functions.sum(&quot;sales_sum&quot;).as(&quot;total_amount&quot;)
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          120
        </td>
        <td>
          3419
          -
          3467
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Column.as
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.functions.sum(&quot;no_of_visit&quot;).as(&quot;no_of_visit&quot;)
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          122
        </td>
        <td>
          3517
          -
          3528
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.types.IntegerType
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.types.IntegerType
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          124
        </td>
        <td>
          3108
          -
          3534
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Dataset.orderBy
        </td>
        <td style="background: #AEF1AE">
          customerWiseweeklyStatus.groupBy(&quot;sales_week_number&quot;).agg(org.apache.spark.sql.functions.count(&quot;customer_id&quot;).cast(org.apache.spark.sql.types.IntegerType).as(&quot;customer_count&quot;), org.apache.spark.sql.functions.sum(&quot;offer_received_count&quot;).as(&quot;total_offer_received&quot;), org.apache.spark.sql.functions.sum(&quot;offer_redeemed_count&quot;).as(&quot;total_offer_redeemed&quot;), org.apache.spark.sql.functions.sum(&quot;sales_sum&quot;).as(&quot;total_amount&quot;), org.apache.spark.sql.functions.sum(&quot;no_of_visit&quot;).as(&quot;no_of_visit&quot;)).orderBy(org.apache.spark.sql.functions.col(&quot;sales_week_number&quot;).cast(org.apache.spark.sql.types.IntegerType).asc)
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          121
        </td>
        <td>
          3491
          -
          3510
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;sales_week_number&quot;
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          123
        </td>
        <td>
          3487
          -
          3533
        </td>
        <td>
          Select
        </td>
        <td>
          org.apache.spark.sql.Column.asc
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.functions.col(&quot;sales_week_number&quot;).cast(org.apache.spark.sql.types.IntegerType).asc
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          126
        </td>
        <td>
          3667
          -
          3733
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #F0ADAD">
          throw new scala.`package`.NullPointerException(&quot;customerWiseweeklyStatus is null&quot;)
        </td>
      </tr><tr>
        <td>
          87
        </td>
        <td>
          127
        </td>
        <td>
          3885
          -
          4151
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Dataset.select
        </td>
        <td style="background: #AEF1AE">
          transaction.join(customerCall, transaction.apply(&quot;customer_id&quot;).===(customerCall.apply(&quot;cust_id&quot;)), &quot;inner&quot;).select(&quot;transaction_id&quot;, &quot;customer_id&quot;, &quot;product_id&quot;, &quot;store_id&quot;, &quot;offer_id&quot;, &quot;sales&quot;, &quot;date&quot;, &quot;sales_week_number&quot;, &quot;day_of_sales_week&quot;, &quot;age_group&quot;)
        </td>
      </tr><tr>
        <td>
          98
        </td>
        <td>
          145
        </td>
        <td>
          4403
          -
          5049
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Try.apply
        </td>
        <td style="background: #AEF1AE">
          scala.util.Try.apply[org.apache.spark.sql.DataFrame]({
  val resultOfAgeGroup: org.apache.spark.sql.DataFrame = transactionAgeGroup.groupBy(&quot;day_of_sales_week&quot;, &quot;age_group&quot;).agg(org.apache.spark.sql.functions.count(&quot;day_of_sales_week&quot;).as(&quot;days_count&quot;));
  val resultOfAgeGroupFetch: org.apache.spark.sql.DataFrame = resultOfAgeGroup.groupBy(&quot;age_group&quot;).agg(org.apache.spark.sql.functions.max(&quot;days_count&quot;).as(&quot;total&quot;));
  val resultAgeGroup: org.apache.spark.sql.DataFrame = resultOfAgeGroup.join(resultOfAgeGroupFetch, resultOfAgeGroup.apply(&quot;age_group&quot;).===(resultOfAgeGroupFetch.apply(&quot;age_group&quot;)).&amp;&amp;(resultOfAgeGroup.apply(&quot;days_count&quot;).===(resultOfAgeGroupFetch.apply(&quot;total&quot;)))).select(resultOfAgeGroup.apply(&quot;day_of_sales_week&quot;), resultOfAgeGroup.apply(&quot;age_group&quot;), resultOfAgeGroupFetch.apply(&quot;total&quot;));
  resultAgeGroup
})
        </td>
      </tr><tr>
        <td>
          99
        </td>
        <td>
          128
        </td>
        <td>
          4467
          -
          4486
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;day_of_sales_week&quot;
        </td>
      </tr><tr>
        <td>
          99
        </td>
        <td>
          129
        </td>
        <td>
          4488
          -
          4499
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;age_group&quot;
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          131
        </td>
        <td>
          4439
          -
          4561
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.RelationalGroupedDataset.agg
        </td>
        <td style="background: #AEF1AE">
          transactionAgeGroup.groupBy(&quot;day_of_sales_week&quot;, &quot;age_group&quot;).agg(org.apache.spark.sql.functions.count(&quot;day_of_sales_week&quot;).as(&quot;days_count&quot;))
        </td>
      </tr><tr>
        <td>
          100
        </td>
        <td>
          130
        </td>
        <td>
          4517
          -
          4560
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Column.as
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.functions.count(&quot;day_of_sales_week&quot;).as(&quot;days_count&quot;)
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          134
        </td>
        <td>
          4597
          -
          4669
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.RelationalGroupedDataset.agg
        </td>
        <td style="background: #AEF1AE">
          resultOfAgeGroup.groupBy(&quot;age_group&quot;).agg(org.apache.spark.sql.functions.max(&quot;days_count&quot;).as(&quot;total&quot;))
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          133
        </td>
        <td>
          4639
          -
          4668
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Column.as
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.sql.functions.max(&quot;days_count&quot;).as(&quot;total&quot;)
        </td>
      </tr><tr>
        <td>
          101
        </td>
        <td>
          132
        </td>
        <td>
          4622
          -
          4633
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;age_group&quot;
        </td>
      </tr><tr>
        <td>
          103
        </td>
        <td>
          136
        </td>
        <td>
          4786
          -
          4820
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Dataset.apply
        </td>
        <td style="background: #AEF1AE">
          resultOfAgeGroupFetch.apply(&quot;age_group&quot;)
        </td>
      </tr><tr>
        <td>
          103
        </td>
        <td>
          135
        </td>
        <td>
          4769
          -
          4780
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;age_group&quot;
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          137
        </td>
        <td>
          4852
          -
          4864
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;days_count&quot;
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          140
        </td>
        <td>
          4752
          -
          4900
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Column.&amp;&amp;
        </td>
        <td style="background: #AEF1AE">
          resultOfAgeGroup.apply(&quot;age_group&quot;).===(resultOfAgeGroupFetch.apply(&quot;age_group&quot;)).&amp;&amp;(resultOfAgeGroup.apply(&quot;days_count&quot;).===(resultOfAgeGroupFetch.apply(&quot;total&quot;)))
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          139
        </td>
        <td>
          4835
          -
          4900
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Column.===
        </td>
        <td style="background: #AEF1AE">
          resultOfAgeGroup.apply(&quot;days_count&quot;).===(resultOfAgeGroupFetch.apply(&quot;total&quot;))
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          138
        </td>
        <td>
          4870
          -
          4900
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Dataset.apply
        </td>
        <td style="background: #AEF1AE">
          resultOfAgeGroupFetch.apply(&quot;total&quot;)
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          142
        </td>
        <td>
          4958
          -
          4987
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Dataset.apply
        </td>
        <td style="background: #AEF1AE">
          resultOfAgeGroup.apply(&quot;age_group&quot;)
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          141
        </td>
        <td>
          4919
          -
          4956
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Dataset.apply
        </td>
        <td style="background: #AEF1AE">
          resultOfAgeGroup.apply(&quot;day_of_sales_week&quot;)
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          144
        </td>
        <td>
          4707
          -
          5020
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Dataset.select
        </td>
        <td style="background: #AEF1AE">
          resultOfAgeGroup.join(resultOfAgeGroupFetch, resultOfAgeGroup.apply(&quot;age_group&quot;).===(resultOfAgeGroupFetch.apply(&quot;age_group&quot;)).&amp;&amp;(resultOfAgeGroup.apply(&quot;days_count&quot;).===(resultOfAgeGroupFetch.apply(&quot;total&quot;)))).select(resultOfAgeGroup.apply(&quot;day_of_sales_week&quot;), resultOfAgeGroup.apply(&quot;age_group&quot;), resultOfAgeGroupFetch.apply(&quot;total&quot;))
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          143
        </td>
        <td>
          4989
          -
          5019
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.Dataset.apply
        </td>
        <td style="background: #AEF1AE">
          resultOfAgeGroupFetch.apply(&quot;total&quot;)
        </td>
      </tr><tr>
        <td>
          111
        </td>
        <td>
          146
        </td>
        <td>
          5128
          -
          5189
        </td>
        <td>
          Throw
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          throw new scala.`package`.NullPointerException(&quot;transactionAgeGroup is null&quot;)
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>